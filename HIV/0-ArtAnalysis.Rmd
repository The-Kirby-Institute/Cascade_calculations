---
title: "Merging and Analysis of Australian ART Data"
author: "Richard T. Gray"
date: '`r format(Sys.Date(), format="%d %B %Y")`'
output: 
  word_document:
    pandoc_args: --output="docs/ART_analysis.docx"
---

This script explores the number of people taking antiretroviral therapy 
(ART) in Australia over 2000-2020. It estimates the number taking ART 
during each year by merging and fitting to multiple data sources. 

1. Australian HIV Observational Database (AHOD) which provides estimates for ART
use up to 2012. The estimates over 2010-2012 are actually projections rather
than estimates from raw data.
2. The Pharmaceutical Benefits Scheme (PBS) 10% longitudinal sample provided by
the company Prospection. This data is only available since 2013. It is
considered a more reliable as it is a more direct estimate. As the PBS data does
not include people who are ineligible for Medicare there is the option to add
the estimates for the number of PLHIV ineligible for Medicare from the NAPWHA
and KI report (from: https://napwha.org.au/medicare-ineligibles/) to the PBS
data.
3. The Pharmaceutical Benefits Scheme (PBS) 100% longitudinal sample provided to
the Kirby Institute directly from the department of Health. This data is only
available from 2014. This data is considered to be the most reliable and direct
estimate. Though there is uncertainty given the difficulties in cleaning the
data to remove ART drug scripts used for other purposes such as Hep B, HIV PrEP
and PEP.

The primary purpose of this analysis is to explore how to cover the change over
period from the AHOD estimates to the PBS data. The results are reported in the
Australian HIV Cascade manuscript.

```{r knitr_options, include=FALSE} 
knitr::opts_chunk$set(echo = FALSE, 
  warning = FALSE, 
  message = FALSE, 
  include = FALSE) 
```


```{r initialization} 
# Restart R and set working directory to source file location

# Various directories
basePath <- getwd() #dirname(getwd())
dataFolder <- file.path(basePath, "data")
#outputFolder <- file.path(basePath, "data")
figFolder <- file.path(basePath, "output","figures")
resultsFolder <- file.path(basePath, "output")
Rcode <- file.path(dirname(basePath), "code") 
HIVcode <- file.path(basePath, "code")

# Load standard libraries, key functions and options
source(file.path(Rcode, "LoadLibrary.R"), echo=TRUE)
source(file.path(Rcode, "DataLibraries.R"), echo=TRUE)
source(file.path(Rcode, "PlotOptions.R"), echo=TRUE)
source(file.path(Rcode, "TidyLongitudinal.R"), echo=TRUE)
source(file.path(Rcode, "AgeCat.R"), echo=TRUE)
LoadLibrary(cowplot)
LoadLibrary(captioner)


# Script parameters
ProspectionDataYear <- 2019 # Lastest Propsection data (last year)
PbsDataYear <- 2023  # Year of latest PBS data  
analysisYear <- 2020 # If want to do fits for data prior to dataYear
                     # Generally only need to do fits up to 2020 but 
                     # data can retrospectively change  

# For analysisYear == 2020 the data used is AHOD prior 2013, Prospection 
# 10% for 2013, and PBS 100% after 2013. We only consider the uncertainty in 
# the Prospection data in 2013. 

saveResults <- TRUE

filterSamples <- FALSE # Filter samples which go outside the PBS error 
                       # bounds for pharmDash data. Only used for 2013
                       # Prospection data. 

# Add temporary residents - Prior to 2018 we had two estimates one from the
# ATRAS study which has been published and one based on personal 
# communication with Aaron Cogle who did a survey for NAPWHA. In March 2019, 
# NAPHWA and KI produced a report providing more detailed estimates of the 
# number of temporary residents (Medicare ineligible) taking ART. The results 
# from this report were used in the 2018 estimates and updated for the 2019 
# estimates.
# 
# The report is available from: https://napwha.org.au/medicare-ineligibles/

addTempResidents <- TRUE 

```

```{r loaddata}
# Load the ART data
artEstimates <- read.csv(file.path(dataFolder, "AHOD_ART_estimates.csv"))

if (analysisYear < 2020) {
  pbsFile <- file.path(dataFolder,
    paste0("pharmdash_HIVpatients_clean-", dataYear,
      ".csv"))
  
  pbsData <- read.csv(pbsFile, as.is = c(1, 2))
  
} else {
  prospectionFile <- file.path(dataFolder,
    paste0("pharmdash_HIVpatients_clean-", ProspectionDataYear,
      ".csv"))
  
  pbsFile <- file.path(dataFolder,
    paste0("pbs_art_clean-", PbsDataYear,
      ".csv"))
  
  prospectionData <- read.csv(prospectionFile)
  pbsData <- read.csv(pbsFile, as.is = c(1, 2)) 
  
  # Need to add Prospection 2013 data to pbsData
  for (ii in 1:nrow(pbsData)) {
    
    temp <- prospectionData[ii,]
    
    pbsData[pbsData$gender == temp$gender & 
        pbsData$state == temp$state, ]$X2013 <- temp$X2013
    
  }
}

if (addTempResidents) {
  # Load from file ATRAS estimates merged with NAPHWA estimates in March 
  # 2019 report.
  tempResData <- read.csv(file.path(dataFolder,
    paste0("ART_medicare_ineligible-", PbsDataYear, ".csv"))) |>
    filter(year <= analysisYear) |>
    dplyr::select(-notes)
  
} else {
  tempResData$value <- 0
  tempResData$lower <- 0
  tempResData$upper <- 0
}

# Clean ART data ---------------------------------------------------------

# First simplify column names
colnames(artEstimates) <- c("year", "ahod")

# Add national PBS data
tempPbs <- pbsData %>% 
  filter(gender == "all", state == "all") %>%
  gather("year", "pbs", 3:ncol(pbsData)) %>%
  select(year, pbs)

# Replace year strings with year values
tempPbs$year <- unlist(lapply(tempPbs$year, function(x)
  as.numeric(strsplit(as.vector(x), 'X')[[1]][2])))

# Add the PBS data to artEstimates
artEstimates <- full_join(artEstimates, tempPbs, by = "year") |>
  filter(year <= analysisYear)

# Add upper and lower bounds for the PBS data
if (analysisYear < 2019) {
  popData <- read_excel(file.path(dirname(dirname(dataFolder)), "data",
    "ABS_population_sizes.xlsx"),
    sheet = 2)
} else {
  popData <- read_csv(file.path(dirname(dirname(dataFolder)), "data",
    "ABS_population_sizes_PharmDash-2019.csv"))
}

source(file.path(HIVcode, "pharmDashError.R"), echo=TRUE)

# Loop through years appending lower and upper PBS estimates
if (analysisYear < 2020) {
  pbsYears <- 2013:PbsDataYear 
  prospectionYears <- pbsYears
} else {
  # Prospection data only used for 2013 rest is PBS 100% data
  pbsYears <- 2013:PbsDataYear 
  prospectionYears <- 2013
}

for (nyear in pbsYears) {
  
  numArt <- filter(artEstimates, year == nyear)$pbs
  numPop <- filter(popData, year == nyear, population == "all")$erp
  
  if (nyear %in% prospectionYears) {
    error <- PharmDashError(numPop, numArt)
    
    artEstimates$pbslower[artEstimates$year == nyear] <- error$lower
    artEstimates$pbsupper[artEstimates$year == nyear] <- error$upper
  }
}

# Add temporary residents to PBS data
artEstimates$pbs[artEstimates$year %in% pbsYears] <-
  artEstimates$pbs[artEstimates$year %in% pbsYears] +
  tempResData$value
artEstimates$pbslower[artEstimates$year %in% pbsYears] <-
  artEstimates$pbslower[artEstimates$year %in% pbsYears] +
  tempResData$lower
artEstimates$pbsupper[artEstimates$year %in% pbsYears] <-
  artEstimates$pbsupper[artEstimates$year %in% pbsYears] +
  tempResData$upper

# Add other variables ----------------------------------------------------

# Add some variables for specific data
artEstimates$ahodraw <- NA
artEstimates$all <- NA
artEstimates$ahodraw[1:11] <- artEstimates$ahod[1:11] # trust AHOD up to 2010
artEstimates$all[1:13] <- artEstimates$ahod[1:13]
artEstimates$all[14:nrow(artEstimates)] <- 
  artEstimates$pbs[14:nrow(artEstimates)]

# Filter out data for fitting ---------------------------------------------
# artEstimates <- artEstimates %>%
#   filter(year <= dataYear)
pbsYears <- pbsYears[pbsYears <= analysisYear]

```

## Fitting 

```{r Fit curves}
# Explore fitting a function to the data. Don't need to do the various
# logistic regressions because these can be done using ggplot with 
# geom_smooth. Rather we explore different fitting functions

# Functions to fit
fitFunc<- function(x, a, b, c, d) {
  # A four parameter logistic function
  return((b-a) / (1 + exp(-d * (x - c))) + a)
}

# Specify our x and y data for fitting
ydata <- artEstimates$all
xdata <- artEstimates$year

# Set weights to reflect PBS data is likely to be more accurate
# With first 11 AHOD estimates accurate, the next two (2011-2012) AHOD 
# estimates inaccurate.  
weights <- c(rep(0.66, 11), rep(0.33, 2), rep(1, length(pbsYears)))

# Weighted logistic regression -------------------------------------------

# For comparison add a weighted regression fit
fitWlm <- lm(ydata ~ xdata, weights = weights)
artEstimates$fitwlm <- predict(fitWlm, xdata = xdata)

# GLM --------------------------------------------------------------------

# Try various general lineraized models

# First try a poisson regression
fitGlmPois <- glm(all ~ year, data = artEstimates, 
  family = poisson(link = "log"), weights = weights)
artEstimates$fitglmpois <- predict(fitGlmPois, type="response")

# Now try a binomial regression

saturationCoverage <- 30000 # estimate of saturation coverage

# Take the difference because we are taking the log
artEstimates$diffbin <- saturationCoverage - artEstimates$all 

# Now do a binomial fit
fitGlmBin <- glm(cbind(all, diffbin) ~ year, data = artEstimates, 
  family = binomial(link = "logit"), weights = weights)
artEstimates$fitglmbin <- predict(fitGlmBin, type="response") * 
  saturationCoverage

# Remove difference calculation
artEstimates <- select(artEstimates, -diffbin)

# Fit a specific function ------------------------------------------------

# Functions to fit (logistic)
fitFunc<- function(x, a, b, c, d) {
  # A four parameter logistic function
  return((b-a) / (1 + exp(-d * (x - c))) + a)
}

# Do the fitting 
if (analysisYear == 2014) {
  # Note for 2014 data: nls seems to have lots of problems fitting to
  # the full four parameter logistic function but works if we force one of 
  # of the parameters to a specific value. Here we set the inflection point.
  # For 2014 data it appears to be insensitive to a value greater than 2015. 
  inflectionYear <- 2020
  fitLog <- nls(ydata ~ fitFunc(xdata, a, b, inflectionYear, d),
    start = list(a = 5000, b = 30000, d = 0.1),
    weights = weights)
  
  # Note: best fit from Matlab for comparison for AnalysisYear = 2014. 
  # a = 5270, b = 30200, c = 2014.7 d = 0.207) 
  
} else if (analysisYear >= 2017) {
  # For 2017 data and after a four parameter fit can be done but confident 
  # intervals are problematic and mess up code below. We do a 4 parameter 
  # fit first and then fix the inflectionYear value and then refit
  fitLog4 <- nls(ydata ~ fitFunc(xdata, a, b, c, d),
    start = list(a = 5000, b = 30000, c = 2015, d = 0.1),
    weights = weights)
  
  inflectionYear <- coef(fitLog4)["c"]
  fitLog <- nls(ydata ~ fitFunc(xdata, a, b, inflectionYear, d),
    start = list(a = 5000, b = 30000, d = 0.1),
    weights = weights)
  
} else {
  fitLog <- nls(ydata ~ fitFunc(xdata, a, b, c, d),
    start = list(a = 5000, b = 30000, c = 2015, d = 0.1),
    weights = weights)
  
  inflectionYear <- coef(fitLog)["c"]
  warning("fitLog needs to beasssessed for Fit")
}

# Compare to an exponential
fitFuncExp <- function(x, a, b, c) {
  # A three parameter exponential function
  return(a * exp(b * (x - c)))
}

fitExp <- nls(ydata ~ fitFuncExp(xdata, a, b, 2000),
  start = list(a = 6233, b = 0.07),
  weights = weights)


# Add the fits to dataframe 
artEstimates$fitlog <- predict(fitLog, xdata = xdata)
artEstimates$fitexp <- predict(fitExp, xdata = xdata)

# Explore the fit - e.g logfit
# summary(fitLog)
# sum(resid(fitLog)^2)
# confint(fitLog)
```

```{r predictcurves}
# Generate ensemble of curves based on variation in 95% confidence interval
# of estimated parameters values
aRange <- confint(fitLog)[1,]
bRange <- confint(fitLog)[2,]
dRange <- confint(fitLog)[3,]

nsamples <- 10000  # ensure big enough to get enough samples out after 
# filtering
simMatrix <- matrix(0,nsamples, length(xdata))

aSample <- runif(nsamples, aRange[1], aRange[2])
bSample <- runif(nsamples, bRange[1], bRange[2])
dSample <- runif(nsamples, dRange[1], dRange[2])

for (ii in 1:nsamples) {
  simMatrix[ii,] <- fitFunc(xdata,aSample[ii], bSample[ii], 
    inflectionYear, dSample[ii])
  
}

if (filterSamples) {
  # Filter samples which go outside the PBS error bounds for analysisYear
  goodRows <- apply(simMatrix, 1,
    function(x) any(x[length(xdata)] <
        artEstimates$pbsupper[length(xdata)]
      && x[length(xdata)] >
        artEstimates$pbslower[length(xdata)]))
  
  simMatrix <- simMatrix[goodRows, ]
}

# Use function to generate lower and upper bounds for ART numbers for best 
# fitting function
artEstimates$fitmin <- apply(simMatrix, 2, min)
artEstimates$fitlwr95 <- apply(simMatrix, 2, quantile, probs = 0.025)
artEstimates$fitlwriqr <- apply(simMatrix, 2, quantile, probs = 0.25)
artEstimates$fitupriqr <- apply(simMatrix, 2, quantile, probs = 0.75)
artEstimates$fitupr95 <- apply(simMatrix, 2, quantile, probs = 0.975)
artEstimates$fitmax <- apply(simMatrix, 2, max)

# Add relative trends and adjusted values
finalIndex <- nrow(artEstimates)
index2012 <- nrow(filter(artEstimates, year <= 2012))

# Replace 2011:2012 values with fitted values as these were projected 
# anyway and are not direct estimates
artEstimates$alladjust <- artEstimates$all
artEstimates[artEstimates$year %in% c(2011:2012), ]$alladjust <- 
  artEstimates[artEstimates$year %in% c(2011:2012), ]$fitlog 

# Relative ART numbers
artEstimates$rel <- artEstimates$alladjust / 
  artEstimates$alladjust[finalIndex]

artEstimates$rellower <- artEstimates$fitmin / 
  artEstimates$alladjust

artEstimates$relupper <- artEstimates$fitmax / 
  artEstimates$alladjust
```


```{r plotanalysis}
figs <- captioner()

# Adjust plot options
plotOpts <- PlotOptions() + theme(legend.position = "right",
  legend.text = element_text(size = 8),
  legend.title = element_text(size = 9, face = "bold"))

#Set-up colours, labels and shapes for legend aesthetics
cols <- c("ahod" = "blue", "pbs" = "red", "all" = "black", 
  "reg1" = "#99CCFF", "reg2" = "#663399", "reg3" = "#006699",
  "fitreg" = "#003300", "fitexp" = "#006699",
  "fitlog" = "#993333")

labels <- c("ahod" = "AHOD data", 
  "pbs" = "PBS data", 
  "all" = "ART data", 
  "reg1" = "Regression AHOD\n2000-2010",
  "reg2" = "Regression AHOD\n2000-2013", 
  "reg3" = "Regression all data", 
  "fitreg" = "Regression\nweighted", 
  "fitexp" = "Exponential fit",
  "fitlog" = "Logistic fit")

shapes <- c("ahod" = 18, "pbs" = 18, "all" = 18, 
  "reg1" = NA, "reg2" = NA, "reg3" = NA, 
  "fitreg" = NA, "fitexp" = NA, "fitlog" = NA)

# Create a plot for comparing the regression analyses
aesLabels <- c("ahod", "pbs", "fitreg", "reg3", "reg2", "reg1")

regressionPlot <- ggplot(data = artEstimates, aes(x = year, y = ahod)) + 
  geom_point(aes(colour = "ahod", shape = "ahod"), 
    na.rm = TRUE) + 
  geom_point(aes(y = pbs, colour = "pbs", shape = "pbs"), na.rm = TRUE) +
  geom_smooth(aes(y = ahodraw, colour = "reg1", shape = "reg1"),
    method = "lm", se = FALSE, na.rm = TRUE, fullrange = TRUE) + 
  geom_smooth(aes(colour = "reg2", shape = "reg2"), 
    method = "lm", se = FALSE, na.rm = TRUE, fullrange = TRUE) + 
  geom_smooth(aes(y = all, colour = "reg3", shape = "reg3"), 
    method = "lm",  se = FALSE, na.rm = TRUE, fullrange = TRUE) +
  geom_line(aes(y = fitwlm, colour = "fitreg", shape = "fitreg")) + 
  scale_colour_manual(name = "", values = cols,
    labels = labels[aesLabels],
    breaks = aesLabels,
    guide = guide_legend(override.aes = list(
      linetype = c("blank", "blank", 
        rep("solid", 4))))) +
  scale_shape_manual(name = "", values = shapes,
    breaks = aesLabels, 
    labels = labels[aesLabels]) +
  ylim(c(0, NA)) + 
  ylab("Number on ART") + 
  xlab("Year") + 
  plotOpts

fitPlot <- ggplot(data = artEstimates, aes(x = year)) +
  geom_point(aes(y = all, colour = "all", shape = "all"), na.rm = TRUE) +
  geom_line(aes(y = fitexp, colour = "fitexp", shape = "fitexp")) +
  geom_line(aes(y = fitlog, colour = "fitlog", shape = "fitlog")) +
  scale_colour_manual(name = "", values = cols,
    labels = labels[c("all", "fitexp", "fitlog")],
    breaks = c("all", "fitexp", "fitlog"),
    guide = guide_legend(override.aes = list(
      linetype = c("blank", "solid", "solid")))) +
  scale_shape_manual(name = "", values = shapes,
    breaks = c("all", "fitexp", "fitlog"), 
    labels = labels[c("all", "fitexp", "fitlog")]) +
  ylim(c(0, NA)) +
  ylab("Number on ART") +
  xlab("Year") +
  plotOpts

logPlot <- ggplot(data = artEstimates, aes(x = year)) + 
  geom_ribbon(aes(ymin = fitmin, ymax = fitmax, 
    fill = "fitlog1", alpha = "fitlog1")) + 
  geom_ribbon(aes(ymin = fitlwr95, ymax = fitupr95,
    fill = "fitlog2", alpha = "fitlog2")) +
  geom_ribbon(aes(ymin = fitlwriqr, ymax = fitupriqr,
    fill = "fitlog3", alpha = "fitlog3")) +
  geom_point(aes(y = all, colour = "all", shape = "all"), na.rm = TRUE) +
  geom_errorbar(aes(ymin = pbslower, ymax = pbsupper), width = 0.3, 
    color = "black", size = 0.8, na.rm = TRUE) + 
  geom_line(aes(y = fitlog, colour = "fitlog", shape = "fitlog")) +
  scale_colour_manual(name = "Fit", values = cols, 
    breaks = c("all", "fitlog"),
    labels = labels[c("all", "fitlog")],
    guide = guide_legend(override.aes = list(
      linetype = c("blank", "solid")))) +
  scale_shape_manual(name = "Fit", values = shapes[c("all", "fitlog")], 
    breaks = c("all", "fitlog"),
    labels = labels[c("all", "fitlog")]) +
  scale_fill_manual(name = "Range",
    values = c("#993333", "#993333", "#993333"),
    breaks = c("fitlog1", "fitlog2", "fitlog3"),
    labels = c("Range", "95% interval", "IQR")) +
  scale_alpha_manual(name =  "Range",
    values = c(0.2, 0.35, 0.5),
    breaks = c("fitlog1", "fitlog2", "fitlog3"),
    labels = c("Range", "95% interval", "IQR")) +
  ylim(c(0, NA)) +
  ylab("Number on ART") +
  xlab("Year") +
  plotOpts

# Save plots as PNG files - 300 dpi by default
plotWidth <- 12
plotHeight <- 7
plotUnits <- "cm"

# Create a combined figure
fitsFigure <- ggdraw() +
  draw_plot(regressionPlot, 0, 0.5, 0.5, 0.5) +
  draw_plot(fitPlot, 0.5, 0.5, 0.5, 0.5) +
  draw_plot(logPlot, 0.2, 0, 0.6, 0.5) +
  draw_plot_label(c("A", "B", "C"), c(0, 0.5, 0.2), c(1, 1, 0.5),
    size = 12)

figs("fitsFigure", "(A) Linear regression fits to ART data. (B) Comparison 
of exponential and logistic curve fits to ART data. (C) Logistic function
fit with uncertainty.")


```

`r figs("fitsFigure")`
```{r Insert figure, include = TRUE, fig.width = 8, fig.height = 6}
fitsFigure
```

```{r Save results}
if (saveResults) {
  
  # String tag
  if (addTempResidents) {
    trString <- "PBS-Ineligible"
  } else {
    trString <- "PBS"
  }
  
  # Save plots
  ggsave(file.path(figFolder, paste0("Regression_Comparision-", 
    analysisYear, "-", trString, ".png")), plot = regressionPlot,
    width = plotWidth, height = plotHeight, units = plotUnits)
  ggsave(file.path(figFolder, paste0("Fit_Comparison-", 
    analysisYear, "-", trString, ".png")), plot = fitPlot, 
    width = plotWidth, height = plotHeight, units = plotUnits)
  ggsave(file.path(figFolder, paste0("Logistic_Fit-", 
    analysisYear, "-", trString, ".png")), plot = logPlot,
    width = plotWidth, height = plotHeight, units = plotUnits)
  
  ggsave(file.path(figFolder, paste0("ART_Fitting_Figure-", 
    analysisYear, "-", trString, ".png")), plot = fitsFigure,
    width = 8, height = 6, units = "in")
  
  # File directory and file name
  saveString <- file.path(resultsFolder, paste0("ART_Estimates-", 
    analysisYear, "-", trString))
  
  # Write to csv
  write.csv(artEstimates, file = paste0(saveString, ".csv"), 
    row.names = FALSE)
}

```
